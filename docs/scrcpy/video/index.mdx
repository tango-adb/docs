---
sidebar_position: 7
---

import Version from "../version-span";

# Handle video stream

The video socket from Scrcpy server contains the encoded video frames. However, its format depends on the Scrcpy server version and the specified option values.

## Raw mode

Since v1.22, if `sendDeviceMeta` and `sendFrameMeta` options are `false`<Version since="v2.0">, and `sendCodecMeta` option is also `false`</Version>, the server directly returns the encoded video stream without any encapsulations. In this mode, the video stream can be decoded or saved directly.

Otherwise, the video stream contains additional metadata and frame information. The following methods can be used to parse and handle the video stream.

## With `@yume-chan/scrcpy`

If you have a `ReadableStream<Uint8Array>` that reads from the video socket, use `options` to parse the metadata and create a packet stream.

### `parseVideoStreamMetadata`

The first step is to parse the one-time metadata from the video stream. This method will return the metadata and a new stream that contains the remaining data.

```ts transpile
import { ScrcpyOptions2_1, ScrcpyVideoStreamPacket } from "@yume-chan/scrcpy";

const options = new ScrcpyOptions2_1({
  // use the same version and options when starting the server
});

const videoSocket: ReadableStream<Uint8Array>; // get the stream yourself

// Parse video socket metadata
const { metadata: videoMetadata, stream: videoStream } =
  await options.parseVideoStreamMetadata(videoSocket);
```

The `metadata` object contains the following fields:

```ts
interface ScrcpyVideoStreamMetadata {
  deviceName?: string | undefined;
  width?: number | undefined;
  height?: number | undefined;
  codec: ScrcpyVideoCodecId;
}
```

- `deviceName`: The device's model name<Version since="v1.22">, or `undefined` if the `sendDeviceMeta` option is `false`.</Version>.
- `width` and `height`: The size of the first video frame<Version since="v1.22" until='v2.0'>, or `undefined` if the `sendDeviceMeta` option is `false`.</Version><Version since="v2.0">, or `undefined` if the `sendCodecMeta` option is `false`.</Version>.
- `codec`: The codec returned from the server<Version since="v2.0">, or the codec inferred from options if the `sendCodecMeta` option is `false`.</Version>.

When device orientation changes (or when a foldable device folds/unfolds), video capture will be restarted with the new resolution, but the server won't send the metadata again. To keep track of the current video size, it's recommended to parse them from the video stream itself. The exact code depends on the video codec.

The returned `videoStream` is a `ReadableStream<Uint8Array>` that contains the video stream after the metadata<Version since="v1.22" until="v2.0">, or the input stream as-is if the `sendDeviceMeta` option is `false`.</Version><Version since="v2.0">, or the input stream as-is if both `sendDeviceMeta` and `sendCodecMeta` options are `false`.</Version>.

### `createMediaStreamTransformer`

The `createMediaStreamTransformer` method creates a `TransformStream` that parses the video stream into packets.

`parseVideoStreamMetadata` and `createMediaStreamTransformer` are separate methods, because the video and audio stream has the same format, but different metadata.

```ts transpile
const videoPacketStream: ReadableStream<ScrcpyMediaStreamPacket> =
  videoStream.pipeThrough(options.createMediaStreamTransformer());

videoPacketStream
  .pipeTo(
    new WritableStream({
      write(packet: ScrcpyMediaStreamPacket) {
        switch (packet.type) {
          case "configuration":
            // Handle configuration packet
            console.log(packet.data);
            break;
          case "data":
            // Handle data packet
            console.log(packet.keyframe, packet.pts, packet.data);
            break;
        }
      },
    })
  )
  .catch((e) => {
    console.error(e);
  });
```

Similar to [`options.clipboard`](../options/index.mdx#watch-device-clipboard-changes), don't `await` the `pipeTo`. The returned `Promise` only resolves when `videoSocket` ends, but waiting here and not handling other streams will block `videoSocket` so it never ends.

`videoPacketStream` contains two types of packets:

```ts
interface ScrcpyMediaStreamConfigurationPacket {
  type: "configuration";
  data: Uint8Array;
}

interface ScrcpyMediaStreamDataPacket {
  type: "data";
  keyframe?: boolean;
  pts?: bigint;
  data: Uint8Array;
}

type ScrcpyMediaStreamPacket =
  | ScrcpyMediaStreamConfigurationPacket
  | ScrcpyMediaStreamDataPacket;
```

The behavior of the packets depends on the `sendFrameMeta` option:

| Value                                  | `sendFrameMeta: true`                                    | `sendFrameMeta: false` |
| -------------------------------------- | -------------------------------------------------------- | ---------------------- |
| `ScrcpyMediaStreamConfigurationPacket` | Must be the first packet, but can also appear anywhere   | Not exist              |
| `ScrcpyMediaStreamDataPacket.keyframe` | `boolean` indicating if the current packet is a keyframe | `undefined`            |
| `ScrcpyMediaStreamDataPacket.pts`      | `bigint` indicating the presentation timestamp           | `undefined`            |

### Configuration packet

When the encoder is restarted, another configuration packet will be generated.

The `data` field contains the codec-specific configuration information:

* H.264: Sequence Parameter Set (SPS) and Picture Parameter Set (PPS)
* H.265: Video Parameter Set (VPS), Sequence Parameter Set (SPS), and Picture Parameter Set (PPS)
* AV1: The first 3 bytes of `AV1CodecConfigurationRecord` (https://aomediacodec.github.io/av1-isobmff/#av1codecconfigurationbox). The remaining configuration OBUs are in the next data packet.

The client should handle this packet and update the decoder accordingly.

### Data packet

Each data packet contains exactly one encoded frame.

## With `@yume-chan/adb-scrcpy`

When `video` option is not `false`, `AdbScrcpyClient.videoStream` is a `Promise` that resolves to an `AdbScrcpyVideoStream`.

```ts
interface AdbScrcpyVideoStream {
  stream: ReadableStream<ScrcpyMediaStreamPacket>;
  metadata: ScrcpyVideoStreamMetadata;
}
```

It's very similar to the `videoMetadata` and `videoPacketStream` values in the above section, because `AdbScrcpyClient` calls `parseVideoStreamMetadata` and `createMediaStreamTransformer` internally.

```ts transpile
if (client.videoSteam) {
  const { metadata: videoMetadata, stream: videoPacketStream } =
    await client.videoStream;

  videoPacketStream
    .pipeTo(
      new WritableStream({
        write(packet: ScrcpyMediaStreamPacket) {
          switch (packet.type) {
            case "configuration":
              // Handle configuration packet
              console.log(packet.data);
              break;
            case "data":
              // Handle data packet
              console.log(packet.keyframe, packet.pts, packet.data);
              break;
          }
        },
      })
    )
    .catch((e) => {
      console.error(e);
    });
}
```

Check the [With `@yume-chan/scrcpy`](#with-yume-chanscrcpy) section above for how to handle different types of packets.

## Decode and render video

Tango provides packages to decode and render video packets in Web browsers:

- [Tiny H264 decoder](/scrcpy/video/tiny-h264)
- [WebCodecs decoder](/scrcpy/video/web-codecs)

To use these decoders, the `sendFrameMeta` options must be `true` (the default value).

Decoding and playing video outside the browser is out of scope for this library. It will depend on the platform, UI framework, and media library you use.
